{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "The following table indicates the number of 6-point scores in an American rugby match in the 1979 season.\n",
    "\n",
    "![](table1.png)\n",
    "\n",
    "Based on these results, we create a Poisson distribution with the sample mean parameter  = 2.435. Is there any reason to believe that at a .05 level the number of scores is a Poisson variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.491310681109791\n",
      "0.4836889068537302\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "from scipy.stats import poisson\n",
    "\n",
    "# H0: dist ~ poisson(2.435)\n",
    "# H1: dist != poisson(2.435)\n",
    "\n",
    "mu = 2.435\n",
    "alpha = 0.05\n",
    "\n",
    "poisson_dist = poisson(mu)\n",
    "\n",
    "poisson_pmfs = np.array([poisson_dist.pmf(i) for i in range(0,7)])\n",
    "width_tail = np.append(poisson_pmfs, poisson_dist.sf(6))\n",
    "\n",
    "O = np.array([35,99,104,110,62,25,10,3])\n",
    "E = width_tail*448\n",
    "\n",
    "stat, p_value = st.chisquare(O,f_exp=E)\n",
    "print(stat)\n",
    "print(p_value)\n",
    "print(p_value < alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't reject the H0, which means that we can consider a poisson(2.435) distribution\n",
    "# for the number of 6-point scores in an American rugby match in the 1979 season."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BONUS/OPTIONAL - Question 2\n",
    "Let's analyze a discrete distribution. To analyze the number of defective items in a factory in the city of Medellín, we took a random sample of n = 60 articles and observed the number of defectives in the following table:\n",
    "\n",
    "![](table2.png)\n",
    "\n",
    "A poissón distribution was proposed since it is defined for x = 0,1,2,3, .... using the following model:\n",
    "\n",
    "![](image1.png)\n",
    "\n",
    "For some extra insights check the following link: https://online.stat.psu.edu/stat504/node/63/ \n",
    "\n",
    "Does the distribution of defective items follow this distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.00318408274129524",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_44828\\1648109518.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpoisson_pmfs\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mstat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchisquare\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mO\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mf_exp\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36mchisquare\u001b[1;34m(f_obs, f_exp, ddof, axis)\u001b[0m\n\u001b[0;32m   7556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7557\u001b[0m     \"\"\"\n\u001b[1;32m-> 7558\u001b[1;33m     return power_divergence(f_obs, f_exp=f_exp, ddof=ddof, axis=axis,\n\u001b[0m\u001b[0;32m   7559\u001b[0m                             lambda_=\"pearson\")\n\u001b[0;32m   7560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\stats\\_stats_py.py\u001b[0m in \u001b[0;36mpower_divergence\u001b[1;34m(f_obs, f_exp, ddof, axis, lambda_)\u001b[0m\n\u001b[0;32m   7397\u001b[0m                    \u001b[1;34mf\"of {rtol}, but the percent differences are:\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7398\u001b[0m                    f\"{relative_diff}\")\n\u001b[1;32m-> 7399\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   7400\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   7401\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: For each axis slice, the sum of the observed frequencies must agree with the sum of the expected frequencies to a relative tolerance of 1e-08, but the percent differences are:\n0.00318408274129524"
     ]
    }
   ],
   "source": [
    "# your code here\n",
    "mean_sample=(np.array([0*32,15*1,0*2,9*3,4*4]).sum())/60\n",
    "mu=mean_sample\n",
    "\n",
    "\n",
    "poisson_dist = poisson(mu)\n",
    "\n",
    "poisson_pmfs = np.array([poisson_dist.pmf(i) for i in range(0,5)])\n",
    "#width_tail = np.append(poisson_pmfs, poisson_dist.sf(6))\n",
    "\n",
    "O = np.array([32,15,0,9,4])\n",
    "E = poisson_pmfs*60\n",
    "\n",
    "stat, p_value = st.chisquare(O,f_exp=E)\n",
    "print(stat)\n",
    "print(p_value)\n",
    "print(p_value < alpha)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "A quality control engineer takes a sample of 10 tires that come out of an assembly line, and would like to verify on the basis of the data that follows, if the number of tires with defects observed over 200 days, if it is true that 5% of all tires have defects (that is, if the sample comes from a binomial population with n = 10 and p = 0.05). \n",
    "\n",
    "![](table3.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.306179519542763\n",
      "0.01571578339595122\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# your answer here\n",
    "from scipy.stats import binom\n",
    "\n",
    "# H0: dist ~ binom (10,0.05)\n",
    "# H1: dist != binom (10,0.05)\n",
    "\n",
    "alpha = 0.05\n",
    "n = 10\n",
    "p = 0.05\n",
    "\n",
    "binom_dist= binom(n,p)\n",
    "\n",
    "binom_pmfs = np.array([binom_dist.pmf(i) for i in range(0,2)])\n",
    "width_tail = np.append(binom_pmfs, binom_dist.sf(1))\n",
    "\n",
    "O = np.array([138,53,9])\n",
    "E = width_tail*200\n",
    "\n",
    "stat, p_value = st.chisquare(O,f_exp=E)\n",
    "print(stat)\n",
    "print(p_value)\n",
    "print(p_value < alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "A researcher gathers information about the patterns of Physical Activity of children in the fifth grade of primary school of a public school. He defines three categories of physical activity (Low, Medium, High). He also inquires about the regular consumption of sugary drinks at school, and defines two categories (Yes = consumed, No = not consumed). We would like to evaluate if there is an association between patterns of physical activity and the consumption of sugary drinks for the children of this school, at a level of 5% significance. The results are in the following table: \n",
    "\n",
    "![](table4.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.712198008709638\n",
      "0.004719280137040844\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "#your answer here\n",
    "# H0: physical activity and sugary drinks are independet\n",
    "# H1: physical activity and sugary drinks are not independent\n",
    "\n",
    "alpha = 0.05\n",
    "\n",
    "#table = crosstab(physical,sugary)\n",
    "table = np.array([[32, 12], [14,22], [6,9]])\n",
    "\n",
    "stat, p_value, ddof, exp_values = st.chi2_contingency(table)\n",
    "\n",
    "print(stat)\n",
    "print(p_value)\n",
    "print(p_value < alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
